{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 00:10:48.616922: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-03-31 00:10:48.616977: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: mossad-xps\n",
      "2022-03-31 00:10:48.616988: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: mossad-xps\n",
      "2022-03-31 00:10:48.617157: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.86.0\n",
      "2022-03-31 00:10:48.617205: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.86.0\n",
      "2022-03-31 00:10:48.617216: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 470.86.0\n",
      "2022-03-31 00:10:48.617672: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import networkx as nx\n",
    "import stellargraph as sg\n",
    "from stellargraph.mapper import PaddedGraphGenerator\n",
    "from stellargraph.layer import DeepGraphCNN\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPool1D, Dropout, Flatten\n",
    "from tensorflow.keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Graphs --> NetworkX --> Stellargraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graphs_to_stellargraph(graph_uris, graphs_dir):\n",
    "    uri_to_sg_graph = {}\n",
    "    for uri in tqdm(graph_uris):\n",
    "        file_path = os.path.join(graphs_dir, uri.lstrip('http://kglids.org/resource/kaggle/') + '.tsv')\n",
    "        df_spo = pd.read_csv(file_path, delimiter='\\t').astype(str)\n",
    "        node_embeddings = pd.read_pickle(file_path.replace('.tsv', '.pickle'))\n",
    "        g = nx.DiGraph()\n",
    "        df_spo.apply(lambda x: g.add_edge(x['s'], x['o'], type=x['p']), axis=1)\n",
    "        \n",
    "        for node in g.nodes():\n",
    "            g.nodes[node]['features'] = node_embeddings[node]['transE']#['complEx']  # TODO: complEx or transE?\n",
    "    \n",
    "        g = sg.StellarDiGraph.from_networkx(g, edge_type_attr='type', node_features='features')\n",
    "        uri_to_sg_graph[uri] = g\n",
    "    \n",
    "    return uri_to_sg_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_and_evaluate_classification_model(train_graphs, test_graphs, train_labels, test_labels, num_classes, \n",
    "                                            epochs=100, batch_size=50, sysname='KGLiDS'):\n",
    "    gen = PaddedGraphGenerator(graphs=train_graphs + test_graphs)\n",
    "    k = wandb.config.k  # the number of rows for the output tensor\n",
    "    layer_sizes = [wandb.config.gcn_layer_size] * (wandb.config.gcn_layers - 1) + [1]  # last layer is of size 1. \n",
    "    activations = [\"tanh\"] * wandb.config.gcn_layers\n",
    "    dgcnn_model = DeepGraphCNN(\n",
    "        layer_sizes=layer_sizes,\n",
    "        activations=activations,\n",
    "        k=k,\n",
    "        bias=False,\n",
    "        generator=gen,\n",
    "    )\n",
    "    x_inp, x_out = dgcnn_model.in_out_tensors()\n",
    "\n",
    "    x_out = Conv1D(filters=16, kernel_size=sum(layer_sizes), strides=sum(layer_sizes))(x_out)\n",
    "    x_out = MaxPool1D(pool_size=2)(x_out)\n",
    "\n",
    "    x_out = Conv1D(filters=32, kernel_size=5, strides=1)(x_out)\n",
    "\n",
    "    x_out = Flatten()(x_out)\n",
    "\n",
    "    x_out = Dense(units=wandb.config.fc_size, activation=\"relu\")(x_out)  # 128\n",
    "    x_out = Dropout(rate=wandb.config.dropout)(x_out)\n",
    "\n",
    "    predictions = Dense(units=num_classes, activation=\"softmax\")(x_out)\n",
    "\n",
    "    model = Model(inputs=x_inp, outputs=predictions)\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=wandb.config.lr), loss=categorical_crossentropy, metrics=[\"acc\"])\n",
    "\n",
    "    train_gen = gen.flow(\n",
    "        graphs=train_graphs,\n",
    "        targets=train_labels,\n",
    "        batch_size=batch_size,\n",
    "        symmetric_normalization=False,\n",
    "    )\n",
    "\n",
    "    test_gen = gen.flow(\n",
    "        graphs=test_graphs,\n",
    "        targets=test_labels,\n",
    "        batch_size=1,\n",
    "        symmetric_normalization=False,\n",
    "    )\n",
    "\n",
    "    # fit\n",
    "    history = model.fit(train_gen, epochs=epochs, verbose=1, validation_data=test_gen,\n",
    "                        shuffle=True)  # , callbacks=[Metrics(model, test_graphs, test_labels)])\n",
    "    for i in range(len(history.history['loss'])):\n",
    "        wandb.log({\"Epoch\": i + 1, f\"{sysname} Train Loss\": history.history['loss'][i],\n",
    "                   f\"{sysname} Train Acc\": history.history['acc'][i],\n",
    "                   f\"{sysname} Valid Loss\": history.history['val_loss'][i],\n",
    "                   f\"{sysname} Valid Acc\": history.history['val_acc'][i]})\n",
    "    best_epoch = np.argmax(history.history['val_acc'])\n",
    "    wandb.log({f\"{sysname} Best Train Acc\": history.history['acc'][best_epoch],\n",
    "               f\"{sysname} Best Valid Acc\": history.history['val_acc'][best_epoch]})\n",
    "\n",
    "    sg.utils.plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmossadhelali\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mossad/projects/kglids/pipelines/experiments/wandb/run-20220331_001054-i81ikexs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mossadhelali/task4-pipeline-domains/runs/i81ikexs\" target=\"_blank\">eager-brook-1</a></strong> to <a href=\"https://wandb.ai/mossadhelali/task4-pipeline-domains\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/mossadhelali/task4-pipeline-domains/runs/i81ikexs?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f1f6e913a90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"task4-pipeline-domains\", config={'epochs': 30, 'dropout': 0.25, 'lr': 0.0001, 'gcn_layers': 5, 'gcn_layer_size': 32, 'k': 35, 'fc_size': 32})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "543 Pipelines\n",
      "3    150\n",
      "1    148\n",
      "2    140\n",
      "0    105\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n",
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "task = 'task4'\n",
    "\n",
    "\n",
    "# get graph names and classes\n",
    "uris_labels = pd.read_csv(f'{task}_uris_labels.csv')\n",
    "uris_labels = uris_labels[uris_labels['uri'].apply(lambda x: os.path.exists(f'{task}_kglids_graphs/'+x.lstrip('http://kglids.org/resource/kaggle/') + '.tsv'))]\n",
    "uris_labels = uris_labels[uris_labels['uri'].apply(lambda x: os.path.exists(f'{task}_kglids_graphs/'+x.lstrip('http://kglids.org/resource/kaggle/') + '.pickle'))]\n",
    "uris_labels = uris_labels[uris_labels['uri'].apply(lambda x: os.path.exists(f'{task}_graph4code_graphs/'+x.lstrip('http://kglids.org/resource/kaggle/') + '.tsv'))]\n",
    "uris_labels = uris_labels[uris_labels['uri'].apply(lambda x: os.path.exists(f'{task}_graph4code_graphs/'+x.lstrip('http://kglids.org/resource/kaggle/') + '.pickle'))]\n",
    "uris_labels['label'] = uris_labels['label'].astype('category').cat.codes\n",
    "pips = uris_labels['uri'].tolist()\n",
    "labels = uris_labels['label'].tolist()\n",
    "num_pipeline_classes = len(uris_labels['label'].unique())\n",
    "print(len(pips), 'Pipelines')\n",
    "print(uris_labels.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kglids_stellargraph = load_graphs_to_stellargraph(pips, f'{task}_kglids_graphs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph4code_stellargraph = load_graphs_to_stellargraph(pips, f'{task}_graph4code_graphs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a GCN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split to Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names, test_names, train_labels, test_labels = \\\n",
    "train_test_split(pips, labels, train_size=0.8, stratify=labels, random_state=3)\n",
    "encoder = LabelBinarizer()\n",
    "train_labels, test_labels = encoder.fit_transform(train_labels), encoder.fit_transform(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KGLiDS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_and_evaluate_classification_model([kglids_stellargraph[i] for i in train_names],\n",
    "                                        [kglids_stellargraph[i] for i in test_names],\n",
    "                                        train_labels, test_labels, num_classes=num_pipeline_classes, epochs=wandb.config.epochs, \n",
    "                                        batch_size=50, sysname='KGLiDS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphGen4Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_and_evaluate_classification_model([graph4code_stellargraph[i] for i in train_names],\n",
    "                                        [graph4code_stellargraph[i] for i in test_names], \n",
    "                                        train_labels, test_labels, num_classes=num_pipeline_classes, epochs=wandb.config.epochs, \n",
    "                                        batch_size=5, sysname='GraphGen4Code')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
